\newpage
\part{Morpion et Monte Carlo}
\section{Description du problème}
Dans cette partie, on considère le célèbre jeu du Tic Tac Toe qui se joue sur une grille 3$\times$3. Les joueurs alternent tour à tour en plaçant un «X» ou un «O» sur une case vide de la grille. Le premier joueur à aligner trois symboles gagne. Nous allons considérer deux types de joueurs, des joueurs $Random$ qui se contenteront de choisir leurs prochains coups à jouer aléatoirement et des joueurs qui, eux, utiliseront une méthode de $Monte$ $Carlo$.
L'implémentation de ce jeu est basée sur quatre classes : \verb@State@ qui représente l'état du jeu, une classe \verb@Agent@ qui elle, représente le comportement d'un agent. La méthode \verb@get_action@ permet à l'agent de choisir le prochain coup à jouer.

\section{Joueur Aléatoire}
\begin{figure}[ht]
\centering
\includegraphics[width=0.6\textwidth]{Report/sections/Figures/rand_vs_rand.png}
\caption{Espérance de gain pour deux joueurs $Random$}
\label{FigGraphes}
\end{figure}
La stratégie aléatoire consiste à choisir aléatoirement une action parmis les actions possibles, autrement dit, un joueur aléatoire choisira une action en exploitant uniquement les informations du jeu.
On considère une partie comme étant une expérience à deux issus : victoire ou défaite du Joueur 1.
On note $X$ la variable aléatoire qui dénote la victoire du Joueur 1, en cas de victoire, on donne à $X$ la valeur 1, sinon elle prend la valeur 0. Il est évident alors que $X$ suit une loi de Bernoulli, sur la figure ci-dessus, on peut déduire visuellement le paramètre $p$, en effet, en moyenne, le Joueur 1 a une probabilité
$\mathbb{P}$($X$=1) $\simeq$ 0.58 de gagner. On en déduit que X suit une loi de Bernoulli de paramètre $p$ $\simeq$ 0.58 et de variance $\mathbb{V}$($X$)= $p$(1-$p$) $\simeq$ 0.24.

\section{Joueur Monte Carlo}
L'idée générale d'une simulation de $Monte$ $Carlo$ consiste à jouer un certain nombre de parties avec des choix aléatoires puis d'utiliser les résultats de ces parties pour calculer une bonne action à jouer. Lorsqu'un joueur gagne une de ces parties aléatoires, il devra privilégier les actions qui l'ont mené à cette victoire, dans l'espoir de choisir un coup gagnant lors des prochaines parties et éviter les actions qui ont mené son adversaire à la defaite. Une stratégie $Monte$ $Carlo$ échantillonne aléatoirement l'espace de toutes les actions possibles et fait une estimation de l'action qui semble la plus optimale.
\subsection{Implémentation}
Pour implémenter cet algorithme nous avons créer une classe \newline\verb@MonteCarloAgent@ qui hérite de \verb@Agent@ et qui implémente la méthode \verb@get_action@ dans laquelle on recupère d'abord toutes les actions possibles ensuite, pour $N$ itérations, on choisit une action aléatoirement, on recupère l'état du jeu qui sera joué après cela par deux joueurs aléatoires, enfin, on met à jour la récompense associée à cet action selon le cas où elle a conduit à une victoire ou une défaite. La méthode renvoie l'action avec la plus grande récompense.
\subsection{Mise en oeuvre}

%\begin{figure}[htbp]
 %  \begin{subfigure}[b]{0.5\textwidth}
  %      \centering \includegraphics[width=\textwidth]{Report/sections/Figures/mc_first.png}
   %     \caption{Espérance de gain du Joueur Monte Carlo avec un nombre d'échantillonnage égale à 100 et lorsqu'il entame les parties}
    %\end{subfigure}
    %~
    %\begin{subfigure}[b]{0.5\textwidth}
     %   \centering \includegraphics[width=\textwidth]{Report/sections/Figures/mc_last.png}
      %  \caption{Espérance de gain du Joueur Monte Carlo avec un nombre d'échantillonnage égale à 100 et lorsque c'est le joueur adverse qui entame les parties}
    %\end{subfigure}
    %
    %\caption{Comparaison entre un Joueur $Monte$ $Carlo$ et trois joueurs: Un joueur $Random$, un joueur $UCT$ un un joueur %suivant la même stratégie $Monte$ $Carlo$ }
%\end{figure}

On peut observer sur la figure 4-$a$ que le joueur basé sur la méthode $Monte$ $Carlo$ surpasse largement le joueur $Random$ avec plus de 95\% de parties gagnées. Cependant, il existe des situations où gagner est impossible pour le joueur $Monte$ $Carlo$, malgré le fait que sa politique de jeu soit plus intelligente que celle du joueur $Random$, par exemple, la défaite est inévitable si c'est le joueur $Random$ qui entame la partie et qu'il marque la case centrale en premier, dans ce cas, beaucoup de voies seront bloquées dans la grille et donc peu importe la stratégie du joueur, dans le meilleur cas, il fera match nul. $Monte$ $Carlo$ gagne entre 50\% et 70\% des parties jouées contre les joueurs $UCT$ et un autre joueur $Monte$ $Carlo$ avec le même nombre d'échantillonnage.
La figure 4-$b$ illustre très bien l'avantage donné au joueur qui entame la partie étant donnée que son espérance de gain diminue considérablement face aux deux joueurs $Monte$ $Carlo$ et $UCT$ et diminue légèrement face au joueur $Random$. Cela peut s'expliquer, comme précédemment, par le fait qu'il est quasiment impossible de gagner pour un joueur lorsqu'il n'entame pas la partie malgré le fait que sa stratégie de jeu soit plus optimale que celle de son adversaire. Une hiérarchie entre les trois stratégies peut donc être déduite de ces courbes, cependant, ces résultats expérimentaux sont toutefois dépendants d'autres paramètres comme le nombre d'échantillonnage et le facteur d'exploration de l'algorithme $UCT$.
\begin{figure}[!h]
\centering
  \begin{center}
    \subfloat[Espérance de gain du Joueur Monte Carlo avec un nombre d'échantillonnage égale à 100 et lorsqu'il entame les parties]{
      \includegraphics[width=0.5\textwidth]{Report/sections/Figures/mc_first.png}
      \label{sub:}
                         }
    \subfloat[Espérance de gain du Joueur Monte Carlo avec un nombre d'échantillonnage égale à 100 et lorsque c'est le joueur adverse qui entame les partie]{
      \includegraphics[width=0.5\textwidth]{Report/sections/Figures/mc_last.png}
      \label{sub:s}
                        }
    \caption{Comparaison entre un joueur $Monte$ $Carlo$ et trois joueurs: Un joueur $Random$, un joueur $UCT$ un un joueur suivant la même stratégie $Monte$ $Carlo$}
    \label{fig:renonculacees}
  \end{center}
\end{figure}

