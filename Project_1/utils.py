#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import numpy as np
import matplotlib.pyplot as plt
import math

import tic_tac_toe as ttt

def divide(a, b):
    """
    Calculates the division of a by b.
    If the denominator equals 0, then the result is plus infinity.

    --------------------
    args:
        a (float): the numerator

        b (float): the denominator
    --------------------
    return:
        (float): the division of a by b
    --------------------
    """
    try:
        return a / b
    except:
       return float('Inf')

def heuristic(state, move):
    """
    Evaluates the state-move couple and calculates its Monte Carlo and
    all-moves-as-first confidence values.

    --------------------
    args:
        state (State): the current state

        move (tuple[int]): the next move
    --------------------
    return:
        evaltn (float): the couple (state, move) evaluation

        confid_mv (float): the Monte Carlo confidence value

        confid_amaf (float): The all-moves-as-first confidence values
    --------------------
    """
    evaltn = 0
    confid_mc = 0
    confid_amaf = 0
    return evaltn, confid_mc, confid_amaf

def plot(xlabel, ylabel, ys, xs=None, legend=None, show=True):
    if xs is None:
        xs = 1 + np.arange(len(ys))
    plt.plot(xs, ys)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    if legend is not None:
        plt.legend(legend)
    if show:
        plt.show()

def plot_all(xlabel, ylabel, legend, ys, xs=None):
    for i in range(len(ys)):
        plot(xlabel, ylabel, ys[i], xs, legend=None, show=False)
    plt.legend(legend)
    plt.show()

class State_Move:
    """
    Class representing a state-move couple.
    It contains two counters: one for the number of victories and the other
    one for the total number of times this action was selected at this state
    """
    def __init__(self, state, move, evaltn, confid):
        self._state = state
        self._move = move
        self.count = confid
        self.wins = evaltn * confid

    def __repr__(self):
        return f'{self.wins} / {self.count}'

    def add_match(self, winner):
        """
        Updates its internal state according to the result of a simulation.

        --------------------
        args:
            winner (int): the result of the simulation
        --------------------
        return:
            None
        --------------------
        notes:
            In case of defeat, the wins counter decreases, thus implementing
            the idea of avoiding loss at all cost
        --------------------
        """
        self.count += 1
        if winner == 0:
            self.wins += 0.5
        elif self._state.courant == winner:
            self.wins += 1
        else:
            self.wins -= 5

class UCTree:
    """
    Class representing an Upper Confidence Tree.
    TODO
    """
    b = 2. # the heuristic score for Rapid Action Value Estimation
    c = math.sqrt(2.) # the exploration parameter

    def __init__(self, state, my_id=0):
        self.id = my_id
        self.state = state
        self.moves = state.get_actions()
        self.children = {}
        self.mc = {}
        self.amaf = {}
        for mv in self.moves:
            evaltn, confid_mc, confid_amaf = heuristic(state, mv)
            self.children[mv] = None
            self.mc[mv] = State_Move(state, mv, evaltn, confid_mc)
            self.amaf[mv] = State_Move(state, mv, evaltn, confid_amaf)

    def beta_heur(self, move):
        """
        Calculates the value of beta for the evaluation function, i.e. the
        heuristic weighting coefficient for choosing this move at the this
        state.

        --------------------
        args:
            move (tuple[int)]: the move to evaluate
        --------------------
        return:
            (float): the value of beta for the evaluation function
        --------------------
        """
        n_mc = self.mc[move].count
        n_amaf = self.amaf[move].count
        if n_mc == 0:
            return 0.
        return n_amaf / (n_mc + n_amaf + 4 * n_mc * n_amaf * UCTree.b)

    def beta_mc(self, move):
        """
        Calculates the value of beta for the evaluation function in a
        no-AMAF mode.

        --------------------
        args:
            move (tuple[int)]: the move to evaluate
        --------------------
        return:
            (float): the value of beta for the evaluation function
        --------------------
        see:
            beta_heur
        --------------------
        """
        return 0.

    @property
    def t(self):
        """
        Calculates the total number of simulations made from this state.

        --------------------
        return:
            (int): the number of times an action was chosen at this state
        --------------------
        """
        return sum([self.mc[mv].count for mv in self.moves])

    def evaluate(self, move):
        """
        Evaluates the choice of this move at this state for the development
        of a UCT.

        --------------------
        args:
            move (tuple[int]): the move to evaluate at this state
        --------------------
        return:
            (float): the value of the state-move couple
        --------------------
        """
        Q_mc = divide(self.mc[move].wins, self.mc[move].count)
        Q_amaf = divide(self.amaf[move].wins, self.amaf[move].count)
        beta = self.beta_heur(move)
        expl = math.sqrt(divide(math.log(self.t), self.mc[move].count))
        return (1 - beta) * Q_mc + beta * Q_amaf + UCTree.c * expl

    def evaluate_for_dm(self, move):
        """
        Evaluates the choice of this move at this state for decision-making.

        --------------------
        args:
            move (tuple[int]): the move to evaluate at this state
        --------------------
        return:
            (float): the value of the state-move couple
        --------------------
        """
        if self.mc[move].count == 0: return 0.
        return self.mc[move].wins / self.mc[move].count

    def missing_move(self):
        """
        Finds a move that has not been choosen yet.

        --------------------
        args:
            None
        --------------------
        return:
            mv (tuple[int]): the first move for which there is still not a
            node in the tree
        --------------------
        """
        for mv in self.moves:
            if self.children[mv] is None:
                return mv

    def select(self, moves, player):
        """
        Selects a node that meets one of the following conditions:
            - it corresponds to a terminal state
            - it is a leaf
            - it has at least one move that is yet to
                be selected.

        --------------------
        args:
            moves (list[tuple[int]]): a list to which all the moves selected
            during the process will be appended

            player (int): the player that is looking for an optimised stategy
        --------------------
        return:
            (UCTree): the node from which the simulation will begin
        --------------------
        """
        current = self
        state = current.state
        while True:

            # if terminal state
            if current.moves == [] or state.stop():
                return current
            mv = current.missing_move()

            # if a move has not yet been made at this state
            if mv is not None:
                moves.append(mv)
                state = state.next(mv)
                current.children[mv] = UCTree(state, current.id+1)
                return current.children[mv]

            # if non-terminal and complete (all moves selected at least once) node
            sign = player * state.courant
            evals = [sign * current.evaluate(mv) for mv in current.moves]
            mv_index = evals.index(max(evals))
            mv = current.moves[mv_index]
            moves.append(mv)
            state = state.next(mv)

            # if this move has not been selected yet
            if current.children[mv] is None:
                current.children[mv] = UCTree(state, current.id+1)
                return current.children[mv]
            current = current.children[mv]

    def simulate(self, moves):
        """
        Plays out a game, whose intial state is given by the state of the
        root of this tree, between two random players.

        --------------------
        args:
            moves (list[tuple[int]]): the list of all the moves selected since
            the very first state of this tree, i.e. that of the root
        --------------------
        return:
            win (int) : the winner of this playout
        --------------------
        """
        win, log = ttt.Jeu(self.state, ttt.RandomPlayer(), ttt.RandomPlayer()).run()
        for _,mv in log:
            moves.append(mv)
        return win

    def back_propagate(self, leaf, moves, win):
        """
        Back propagates the outcome of the playout from a leaf to the root
        of this tree.

        --------------------
        args:
            leaf (UCTree): the leaf corresponding to the state from which
            the simulation began

            moves (list[tuple[int]]): the list of all the moves selected from
            the root's state to the terminal state of the simulation

            win (int): the winner of the simulation
        --------------------
        return:
            None
        --------------------
        """
        node = self
        t = 0
        while node != leaf:
            move = moves[t]
            node.mc[move].add_match(win)
            exectd = set()
            for mv in moves[t:]:
                if mv not in exectd:
                    exectd.add(mv)
                    node.amaf[mv].add_match(win)
            t += 1
            node = node.children[move]

    def print_espaces(self):
        """
        Prints as many tabs as the value of this tree's id.

        --------------------
        args:
            None
        --------------------
        return:
            None
        --------------------
        notes:
            A tab is considered to be equal to 4 espaces.
        --------------------
        """
        for _ in range(self.id):
            print('    ',end='')

    def plot(self):
        """
        Prints this tree.

        --------------------
        args:
            None
        --------------------
        return:
            None
        --------------------
        see:
            print_espaces
        --------------------
        """
        self.print_espaces()
        print(f'({self.id})', self.state)
        for mv in self.moves:
            if self.children[mv] is not None:
                print() ; self.children[mv].print_espaces()
                print(f'{self.mc[mv]}')
                self.children[mv].plot()
