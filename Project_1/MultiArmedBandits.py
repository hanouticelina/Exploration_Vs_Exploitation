import numpy as np
import matplotlib.pyplot as plt
import argparse

epsilon = 0.1
 
def operate(machine, lever):
    return bernoulli(machine[lever])

def random_algo(rewards, counters):
    return np.random.randint(rewards.size,size=1)[0]

def greedy_algo(rewards, counters):
    return np.argmax(rewards)

def eps_greedy_algo(rewards, counters):
    if bernoulli(epsilon) is True:
        return random_algo(rewards, counters)
    return greedy_algo(rewards, counters)

def ucb_algo(rewards, counters):
    if (np.min(counters) == 0):
        return np.random.choice(np.where(counters == 0)[0], 1)[0]
    t = np.sum(counters)
    return np.argmax( rewards + np.sqrt((2 * np.log(t)) / counters) )
        
def run(get_next_lever, machine, T, initial_rewards): 
    best_lever = np.argmax(machine)
    counters = np.zeros_like(machine)
    estimated_rewards = np.copy(initial_rewards)
    expected_rewards = np.zeros(T)
    earned_rewards = np.zeros(T)
    for t in range(T):
        expected_rewards[t] = operate(machine, best_lever)
        lever = get_next_lever(estimated_rewards, counters)
        earned_rewards[t] = operate(machine, lever)
        estimated_rewards[lever] = (estimated_rewards[lever]*counters[lever] + earned_rewards[t]) / (counters[lever]+1)
        counters[lever] += 1
    regret = expected_rewards - earned_rewards
    return np.cumsum(regret), np.cumsum(earned_rewards)
    
def bernoulli(param):
    return np.random.uniform() < param

def generate_bernoulli_params(N, max_proportion=1.):
    params = np.random.uniform(size=N)
    params.sort()
    proportion = params[-1] * max_proportion / params[-2]
    if proportion < 1.:
        params[:-1] *= proportion
    np.random.shuffle(params)
    return params

def zeroed_initial_rewards(N):
    return np.zeros(N)

def random_initial_rewards(N):
    return np.random.uniform(size=N)
        
def plot(xlabel, ylabel, legend, ys, x=None):
    if x is None:
        x = np.arange(1,1+ys.shape[1])
    for y in ys:
        plt.plot(x, y)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.legend(legend)
    plt.show()
    
def main():
    learning_algos = [random_algo, greedy_algo, eps_greedy_algo, ucb_algo]
    ap = argparse.ArgumentParser()
    ap.add_argument('levers', type=int, help='the number of levers')
    ap.add_argument('epochs', type=int, help='the number of epochs to simulate')
    ap.add_argument('samples', type=int, help='the number of execution samples to take for each algorithm')
    ap.add_argument('-e','--epsilons', type=float, nargs='+', 
                    help='execute the tests of eps-greedy algorithm for the specified epsilon values')
    ap.add_argument('-r', '--rewards', help='the generation mode for initial rewards', 
                    choices=['zeros', 'random'], default='zeros')
    ap.add_argument('-m', '--max-proportion', metavar='PROP', 
                    help='the maximum proportion of the second highest reward to the highest one')
    args = ap.parse_args()
    
    N = args.levers
    T = args.epochs
    S = args.samples
    if args.rewards == 'random':
        initial_rewards = random_initial_rewards(N)
    else:
        initial_rewards = zeroed_initial_rewards(N)
    if args.max_proportion is not None:
        machine = generate_bernoulli_params(N, float(args.proportion))
    else:
        machine = generate_bernoulli_params(N)
    
    if args.epsilons is None:
        cum_regrets = np.zeros([len(learning_algos), T])
        cum_rewards = np.zeros([len(learning_algos), T])
        for i in range(len(learning_algos)):
            for _ in range(S):
                rgs, rws = run(learning_algos[i], machine, T, initial_rewards)
                cum_regrets[i] += rgs
                cum_rewards[i] += rws
            cum_regrets[i] /= S
            cum_rewards[i] /= S
        plot('number of epochs', 'cumulative regret', ['random', 'greedy', r'$\epsilon$-greedy', 'ucb'], cum_regrets)
        plot('number of epochs', 'cumulative reward', ['random', 'greedy', r'$\epsilon$-greedy', 'ucb'], cum_rewards)
    else:
        global epsilon
        legend = [r'$\epsilon$ = ' + f'{e}' for e in args.epsilons]
        cum_regrets_greedy = np.zeros([len(args.epsilons), T])
        cum_rewards_greedy = np.zeros([len(args.epsilons), T])
        for i in range(len(args.epsilons)):
            epsilon = args.epsilons[i]
            for _ in range(S):
                rgs_eps, rws_eps = run(eps_greedy_algo, machine, T, initial_rewards)
                cum_regrets_greedy[i] += rgs_eps
                cum_rewards_greedy[i] += rws_eps
            cum_regrets_greedy[i] /= S
            cum_rewards_greedy[i] /= S
        plot('number of epochs', 'cumulative regret', legend, cum_regrets_greedy)
        plot('number of epochs', 'cumulative reward', legend, cum_rewards_greedy)
    
if __name__ == "__main__":
    main()
